{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: False\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in each column\n",
    "print(\"Missing values:\", df.isna().sum().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of target variable\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x=\"Target\")\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nnum_columns = len(df.columns)\\nplt.figure(figsize=(20, 4 * num_columns))\\n\\nfor i, col in enumerate(df.columns, 1):\\n    plt.subplot(num_columns, 3, i)\\n    sns.histplot(df[col], bins=30, kde=True)\\n    plt.title(f\\'Distribution of {col}\\')\\n    plt.tight_layout()\\n\\nplt.show()\\n\\n\\nfor col in df.columns:\\n    length = len(df[col].unique())\\n    #if (length < 10):\\n    print(col,\":\", length)\\n\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting histograms for each column in the dataset\n",
    "\n",
    "'''\n",
    "\n",
    "num_columns = len(df.columns)\n",
    "plt.figure(figsize=(20, 4 * num_columns))\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    plt.subplot(num_columns, 3, i)\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    length = len(df[col].unique())\n",
    "    #if (length < 10):\n",
    "    print(col,\":\", length)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features\n",
    "Name, type, unique count or range\n",
    "\n",
    "Marital Status - Categorical - 6\n",
    "Application Mode - Categorical - 18\n",
    "Application Order - Continuous - 0 to 10\n",
    "Course - Categorical - 17\n",
    "Daytime/evening attendance - binary - 2\n",
    "Previous qualifications - Categorical - 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing data shape (2541, 185) (1089, 185) (2541,) (1089,)\n",
      "Total Columns:  185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def encode_target(x):\n",
    "    if x == \"Graduate\":\n",
    "        return 1\n",
    "    elif x == \"Dropout\":\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df = df[df['Target'].isin(['Dropout', 'Graduate'])]\n",
    "\n",
    "prepared_df = pd.DataFrame()\n",
    "\n",
    "# one hot encoding for categorical variables with small number of unique values\n",
    "# 7594 with all of these from \n",
    "one_hot_app_mode = pd.get_dummies(df['Application mode'], prefix='Application mode')\n",
    "one_hot_encoded_marital = pd.get_dummies(df['Marital status'], prefix='Marital status')\n",
    "one_hot_encoded_mother_qual = pd.get_dummies(df[\"Mother's qualification\"], prefix=\"Mother's qualification\")\n",
    "one_hot_encoded_father_qual = pd.get_dummies(df[\"Father's qualification\"], prefix=\"Father's qualification\")\n",
    "one_hot_encoded_mother_occ = pd.get_dummies(df[\"Mother's occupation\"], prefix=\"Mother's occupation\")\n",
    "one_hot_encoded_father_occ = pd.get_dummies(df[\"Father's occupation\"], prefix=\"Father's occupation\")\n",
    "one_hot_encoded_nationality = pd.get_dummies(df[\"Nacionality\"], prefix=\"Nacionality\")\n",
    "\n",
    "prepared_df = pd.concat([prepared_df, one_hot_encoded_marital, one_hot_encoded_mother_qual, one_hot_encoded_father_qual, one_hot_encoded_mother_occ, one_hot_encoded_father_occ, one_hot_encoded_nationality], axis=1)\n",
    "\n",
    "# ordinal variables\n",
    "ordinal_column_names = ['Application order']\n",
    "prepared_df = pd.concat([prepared_df, df[ordinal_column_names]], axis=1)\n",
    "\n",
    "# binary variables\n",
    "binary_column_names = ['Daytime/evening attendance\\t', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', 'Gender', 'Scholarship holder', 'International']\n",
    "prepared_df = pd.concat([prepared_df, df[binary_column_names]], axis=1)\n",
    "\n",
    "# continuous variables\n",
    "continuous_column_names = ['Admission grade', 'Age at enrollment', 'Unemployment rate', 'Inflation rate', 'GDP']\n",
    "prepared_df = pd.concat([prepared_df, df[continuous_column_names]], axis=1)\n",
    "\n",
    "curricular_units_cols = [col for col in df.columns if col.startswith(\"Curricular units\")]\n",
    "prepared_df = pd.concat([prepared_df, df[curricular_units_cols]], axis=1)\n",
    "\n",
    "# encoding the target column\n",
    "df_target = df['Target'].apply(encode_target)\n",
    "# print(df_target)\n",
    "\n",
    "x = prepared_df\n",
    "y = df_target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training and testing data shape\", x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "print(\"Total Columns: \", len(prepared_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns after removing highly correlated columns:  167\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = prepared_df.corr()\n",
    "\n",
    "# flatten the correlation matrix\n",
    "correlation_df = correlation_matrix.unstack().reset_index()\n",
    "\n",
    "correlation_df.columns = ['Variable_1', 'Variable_2', 'Correlation']\n",
    "\n",
    "# sort the DataFrame on the absolute value of the correlation\n",
    "correlation_df['Abs_Correlation'] = correlation_df['Correlation'].abs()\n",
    "\n",
    "# remove correlation of variables with themselves\n",
    "correlation_df = correlation_df[correlation_df['Variable_1'] != correlation_df['Variable_2']]\n",
    "\n",
    "# remove duplicates\n",
    "correlation_df[['Variable_1', 'Variable_2']] = np.sort(correlation_df[['Variable_1', 'Variable_2']], axis=1)\n",
    "correlation_df = correlation_df.drop_duplicates(subset=['Variable_1', 'Variable_2'])\n",
    "\n",
    "# find high correlation\n",
    "high_corr_pairs = correlation_df[correlation_df['Correlation'].abs() > 0.7]\n",
    "\n",
    "# find columns names to drop\n",
    "variables_to_drop = set()\n",
    "for _, row in high_corr_pairs.iterrows():\n",
    "    if row['Variable_1'] not in variables_to_drop and row['Variable_2'] not in variables_to_drop:\n",
    "        variables_to_drop.add(row['Variable_1'])\n",
    "\n",
    "prepared_df_filtered = prepared_df.drop(columns=variables_to_drop)\n",
    "\n",
    "print(\"Total Columns after removing highly correlated columns: \", len(prepared_df_filtered.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.9118457300275482\n",
      "Baseline accuracy: 0.6198347107438017\n",
      "Accuracy for each fold:\n",
      "[0.91184573 0.92286501 0.89807163 0.90358127 0.90909091 0.90082645\n",
      " 0.87878788 0.91735537 0.90909091 0.89807163]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"score: \", model.score(x_test, y_test))\n",
    "\n",
    "# find proportion in test set\n",
    "class_proportions = y_test.value_counts(normalize=True)\n",
    "baseline_accuracy = class_proportions.max()\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=10)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Accuracy for each fold:\")\n",
    "print(scores)\n",
    "\n",
    "#for feature, coef in zip(x_train.columns, model.coef_[0]):\n",
    "#    print(feature, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with multicollinearity removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.859504132231405\n",
      "Baseline accuracy: 0.6198347107438017\n",
      "Accuracy for each fold:\n",
      "[0.91184573 0.92286501 0.89807163 0.90358127 0.90909091 0.90082645\n",
      " 0.87878788 0.91735537 0.90909091 0.89807163]\n"
     ]
    }
   ],
   "source": [
    "x_filtered = prepared_df_filtered\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_filtered, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"score: \", model.score(x_test, y_test))\n",
    "\n",
    "# find proportion in test set\n",
    "class_proportions = y_test.value_counts(normalize=True)\n",
    "baseline_accuracy = class_proportions.max()\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=10)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Accuracy for each fold:\")\n",
    "print(scores)\n",
    "\n",
    "#for feature, coef in zip(x_train.columns, model.coef_[0]):\n",
    "#    print(feature, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Dev\\stats-for-ai-final-project\\Keller_Analysis.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dev/stats-for-ai-final-project/Keller_Analysis.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_train_const[bool_cols] \u001b[39m=\u001b[39m x_train_const[bool_cols]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dev/stats-for-ai-final-project/Keller_Analysis.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Fit the logistic regression model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dev/stats-for-ai-final-project/Keller_Analysis.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_sm_filtered \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mLogit(y_train, x_train_const)\u001b[39m.\u001b[39;49mfit()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dev/stats-for-ai-final-project/Keller_Analysis.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# View the summary of the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/stats-for-ai-final-project/Keller_Analysis.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(model_sm_filtered\u001b[39m.\u001b[39msummary())\n",
      "File \u001b[1;32mc:\\Users\\kflin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2599\u001b[0m, in \u001b[0;36mLogit.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   2596\u001b[0m \u001b[39m@Appender\u001b[39m(DiscreteModel\u001b[39m.\u001b[39mfit\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m)\n\u001b[0;32m   2597\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, start_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton\u001b[39m\u001b[39m'\u001b[39m, maxiter\u001b[39m=\u001b[39m\u001b[39m35\u001b[39m,\n\u001b[0;32m   2598\u001b[0m         full_output\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, disp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2599\u001b[0m     bnryfit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(start_params\u001b[39m=\u001b[39;49mstart_params,\n\u001b[0;32m   2600\u001b[0m                           method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2601\u001b[0m                           maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m   2602\u001b[0m                           full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[0;32m   2603\u001b[0m                           disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[0;32m   2604\u001b[0m                           callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m   2605\u001b[0m                           \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2607\u001b[0m     discretefit \u001b[39m=\u001b[39m LogitResults(\u001b[39mself\u001b[39m, bnryfit)\n\u001b[0;32m   2608\u001b[0m     \u001b[39mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[1;32mc:\\Users\\kflin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m mlefit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(start_params\u001b[39m=\u001b[39;49mstart_params,\n\u001b[0;32m    244\u001b[0m                      method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m    245\u001b[0m                      maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m    246\u001b[0m                      full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[0;32m    247\u001b[0m                      disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[0;32m    248\u001b[0m                      callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    249\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m mlefit\n",
      "File \u001b[1;32mc:\\Users\\kflin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     Hinv \u001b[39m=\u001b[39m cov_params_func(\u001b[39mself\u001b[39m, xopt, retvals)\n\u001b[0;32m    581\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m full_output:\n\u001b[1;32m--> 582\u001b[0m     Hinv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(\u001b[39m-\u001b[39;49mretvals[\u001b[39m'\u001b[39;49m\u001b[39mHessian\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m/\u001b[39m nobs\n\u001b[0;32m    583\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_hessian:\n\u001b[0;32m    584\u001b[0m     H \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhessian(xopt)\n",
      "File \u001b[1;32mc:\\Users\\kflin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    562\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\kflin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "x_train_const = sm.add_constant(x_train)\n",
    "\n",
    "bool_cols = x_train_const.select_dtypes(include=['bool']).columns\n",
    "x_train_const[bool_cols] = x_train_const[bool_cols].astype(int)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model_sm_filtered = sm.Logit(y_train, x_train_const).fit()\n",
    "\n",
    "# View the summary of the model\n",
    "print(model_sm_filtered.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8705234159779615\n"
     ]
    }
   ],
   "source": [
    "# Things we could try - decision tree, SVM (Support Vector Model), Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRandomForestClassifier = RandomForestClassifier()\n",
    "modelRandomForestClassifier.fit(x_train, y_train)\n",
    "\n",
    "print(modelRandomForestClassifier.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034894398530762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modelDecisionTree = DecisionTreeClassifier()\n",
    "modelDecisionTree.fit(x_train, y_train)\n",
    "\n",
    "print(modelDecisionTree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7897153351698806\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "modelSVM = svm.SVC()\n",
    "modelSVM.fit(x_train, y_train)\n",
    "\n",
    "print(modelSVM.score(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
